{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1f6ba9d",
   "metadata": {},
   "source": [
    "###  Spotify-YouTube 음악 콘텐츠 최적화 전략 수립"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fe9c965",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import mean_squared_error, r2_score, classification_report\n",
    "from scipy import stats\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import warnings\n",
    "import os\n",
    "from datetime import datetime\n",
    "import json\n",
    "import pickle\n",
    "import logging\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4f22c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c198e165",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpotifyYouTubeAnalytics:\n",
    "    def __init__(self, csv_file=None):\n",
    "        self.df = None\n",
    "        self.models = {}\n",
    "        self.kpis = {}\n",
    "        self.conn = None\n",
    "        self.feature_importance = {}\n",
    "        self.model_metrics = {}\n",
    "        \n",
    "        self._create_directories()\n",
    "        \n",
    "        # MLflow 설정\n",
    "        self._setup_mlflow()\n",
    "        \n",
    "        if csv_file:\n",
    "            self.load_and_preprocess_data(csv_file)\n",
    "    \n",
    "    def _create_directories(self):\n",
    "        \"\"\"필요한 디렉토리들을 미리 생성\"\"\"\n",
    "        directories = ['models', 'reports', 'data', 'mlruns']\n",
    "        for directory in directories:\n",
    "            os.makedirs(directory, exist_ok=True)\n",
    "            logger.info(f\"디렉토리 생성/확인: {directory}\")\n",
    "    \n",
    "    def _setup_mlflow(self):\n",
    "        \"\"\"MLflow 설정\"\"\"\n",
    "        mlflow.set_tracking_uri(\"./mlruns\")\n",
    "        try:\n",
    "            mlflow.set_experiment(\"Spotify_YouTube_Analytics\")\n",
    "        except:\n",
    "            mlflow.create_experiment(\"Spotify_YouTube_Analytics\")\n",
    "            mlflow.set_experiment(\"Spotify_YouTube_Analytics\")\n",
    "        \n",
    "    def load_and_preprocess_data(self, csv_file):\n",
    "        \"\"\"데이터 로드 및 전처리\"\"\"        \n",
    "        try:\n",
    "            if not os.path.exists(csv_file):\n",
    "                raise FileNotFoundError(f\"파일을 찾을 수 없습니다: {csv_file}\")\n",
    "            \n",
    "            self.df = pd.read_csv(csv_file)\n",
    "            logger.info(f\"데이터셋 크기: {self.df.shape}\")\n",
    "            \n",
    "            self.df.columns = self.df.columns.str.strip()\n",
    "            \n",
    "            numeric_cols = ['Danceability', 'Energy', 'Key', 'Loudness', 'Speechiness', \n",
    "                           'Acousticness', 'Instrumentalness', 'Liveness', 'Valence', \n",
    "                           'Tempo', 'Duration_ms', 'Stream', 'Views', 'Likes', 'Comments']\n",
    "            \n",
    "            for col in numeric_cols:\n",
    "                if col in self.df.columns:\n",
    "                    self.df[col] = pd.to_numeric(self.df[col], errors='coerce')\n",
    "            \n",
    "            if 'Licensed' in self.df.columns:\n",
    "                self.df['Licensed'] = self.df['Licensed'].astype(bool)\n",
    "            if 'official_video' in self.df.columns:\n",
    "                self.df['official_video'] = self.df['official_video'].fillna(False).astype(bool)\n",
    "            \n",
    "            self.df['Stream'] = self.df['Stream'].fillna(0)\n",
    "            self.df['Views'] = self.df['Views'].fillna(0) \n",
    "            self.df['Likes'] = self.df['Likes'].fillna(0)\n",
    "            self.df['Comments'] = self.df['Comments'].fillna(0)\n",
    "            \n",
    "            audio_features = ['Danceability', 'Energy', 'Loudness', 'Speechiness', \n",
    "                             'Acousticness', 'Instrumentalness', 'Liveness', 'Valence', 'Tempo']\n",
    "            for col in audio_features:\n",
    "                if col in self.df.columns:\n",
    "                    self.df[col] = self.df[col].fillna(self.df[col].median())\n",
    "            \n",
    "            original_size = len(self.df)\n",
    "            self.df = self._remove_outliers(self.df, ['Stream', 'Views', 'Likes'], threshold=3)\n",
    "            logger.info(f\"이상치 제거: {original_size} → {len(self.df)} 행\")\n",
    "            \n",
    "            self._feature_engineering()\n",
    "            \n",
    "            # SQLite 데이터베이스 생성\n",
    "            self.conn = sqlite3.connect('data/spotify_analytics.db')\n",
    "            self.df.to_sql('tracks', self.conn, if_exists='replace', index=False)\n",
    "            \n",
    "            logger.info(f\" 전처리 완료 - 최종 데이터 크기: {self.df.shape}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\" 데이터 로드 중 오류: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    def _remove_outliers(self, df, columns, threshold=3):\n",
    "        \"\"\"이상치 제거\"\"\"\n",
    "        for col in columns:\n",
    "            if col in df.columns:\n",
    "                z_scores = np.abs(stats.zscore(df[col]))\n",
    "                df = df[z_scores < threshold]\n",
    "        return df\n",
    "    \n",
    "    def _feature_engineering(self):\n",
    "        \"\"\"피처 엔지니어링\"\"\"\n",
    "    \n",
    "        # 새로운 피처 생성\n",
    "        self.df['duration_minutes'] = self.df['Duration_ms'] / 60000\n",
    "        self.df['audio_positivity'] = (self.df['Danceability'] + self.df['Energy'] + self.df['Valence']) / 3\n",
    "        self.df['audio_complexity'] = self.df['Speechiness'] + self.df['Instrumentalness'] + self.df['Acousticness']\n",
    "        self.df['youtube_engagement'] = (self.df['Likes'] + self.df['Comments']) / (self.df['Views'] + 1)\n",
    "        self.df['cross_platform_ratio'] = self.df['Stream'] / (self.df['Views'] + 1)\n",
    "        self.df['engagement_rate'] = self.df['Likes'] / (self.df['Views'] + 1)\n",
    "        self.df['comment_rate'] = self.df['Comments'] / (self.df['Views'] + 1)\n",
    "        \n",
    "        # 로그 변환\n",
    "        self.df['log_streams'] = np.log1p(self.df['Stream'])\n",
    "        self.df['log_views'] = np.log1p(self.df['Views'])\n",
    "    \n",
    "    def calculate_comprehensive_kpis(self):\n",
    "        \"\"\"전사 KPI 계산\"\"\"\n",
    "        logger.info(\" KPI 계산\")\n",
    "        \n",
    "        self.kpis = {\n",
    "            # 핵심 비즈니스 메트릭\n",
    "            'total_tracks': len(self.df),\n",
    "            'total_artists': self.df['Artist'].nunique(),\n",
    "            'total_streams': self.df['Stream'].sum(),\n",
    "            'total_views': self.df['Views'].sum(),\n",
    "            'avg_streams_per_track': self.df['Stream'].mean(),\n",
    "            'median_streams': self.df['Stream'].median(),\n",
    "            \n",
    "            # 콘텐츠 다양성 지표\n",
    "            'artist_diversity': self.df['Artist'].nunique() / len(self.df),\n",
    "            \n",
    "            # 크로스 플랫폼 성과\n",
    "            'cross_platform_correlation': self.df[(self.df['Stream'] > 0) & (self.df['Views'] > 0)]['Stream'].corr(\n",
    "                self.df[(self.df['Stream'] > 0) & (self.df['Views'] > 0)]['Views']\n",
    "            ),\n",
    "            \n",
    "            # 참여도 지표\n",
    "            'avg_engagement_rate': self.df['engagement_rate'].mean(),\n",
    "            'avg_comment_rate': self.df['comment_rate'].mean(),\n",
    "            \n",
    "            # 오디오 특성 트렌드\n",
    "            'avg_danceability': self.df['Danceability'].mean(),\n",
    "            'avg_energy': self.df['Energy'].mean(),\n",
    "            'avg_valence': self.df['Valence'].mean(),\n",
    "            'avg_tempo': self.df['Tempo'].mean(),\n",
    "        }\n",
    "        \n",
    "        # 오피셜 비디오 임팩트\n",
    "        if 'official_video' in self.df.columns:\n",
    "            official_streams = self.df[self.df['official_video'] == True]['Stream'].mean()\n",
    "            unofficial_streams = self.df[self.df['official_video'] == False]['Stream'].mean()\n",
    "            self.kpis['official_video_lift'] = (official_streams / unofficial_streams) - 1 if unofficial_streams > 0 else 0\n",
    "        \n",
    "        return self.kpis\n",
    "    \n",
    "    def build_prediction_models_with_mlflow(self):\n",
    "        \"\"\"MLflow를 활용한 예측 모델 구축\"\"\"\n",
    "        logger.info(\" MLflow와 함께 예측 모델 구축\")\n",
    "        \n",
    "        # 실험 메타데이터\n",
    "        experiment_info = {\n",
    "            'dataset_size': len(self.df),\n",
    "            'features_count': len(self.df.columns),\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'data_quality_score': (1 - self.df.isnull().sum().sum() / (len(self.df) * len(self.df.columns))) * 100\n",
    "        }\n",
    "        \n",
    "        with mlflow.start_run(run_name=f\"Spotify_Analytics_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"):\n",
    "            mlflow.log_params(experiment_info)\n",
    "            \n",
    "            # 1. 스트림 예측 모델\n",
    "            stream_model, stream_metrics = self._build_stream_prediction_model()\n",
    "            self.models['stream_model'] = stream_model\n",
    "            self.model_metrics.update(stream_metrics)\n",
    "            \n",
    "            # 2. 히트 예측 모델  \n",
    "            hit_model, hit_metrics = self._build_hit_prediction_model()\n",
    "            self.models['hit_model'] = hit_model\n",
    "            self.model_metrics.update(hit_metrics)\n",
    "            \n",
    "            # 3. YouTube 성과 예측 모델\n",
    "            youtube_model, youtube_metrics = self._build_youtube_prediction_model()\n",
    "            self.models['youtube_model'] = youtube_model\n",
    "            self.model_metrics.update(youtube_metrics)\n",
    "            \n",
    "            # 전체 메트릭 로깅\n",
    "            mlflow.log_metrics(self.model_metrics)\n",
    "            \n",
    "            stream_features = [\n",
    "                'Danceability', 'Energy', 'Valence', 'Tempo', 'Loudness',\n",
    "                'Speechiness', 'Acousticness', 'Instrumentalness', 'Liveness',\n",
    "                'duration_minutes', 'audio_positivity', 'audio_complexity',\n",
    "                'log_views', 'youtube_engagement'\n",
    "            ]\n",
    "            input_example = self.df[stream_features].iloc[:5].fillna(0)\n",
    "            \n",
    "            # 모델 아티팩트 저장 \n",
    "            mlflow.sklearn.log_model(\n",
    "            stream_model, \n",
    "            name=\"stream_model\",  \n",
    "            input_example=input_example,\n",
    "            signature=mlflow.models.infer_signature(input_example, stream_model.predict(input_example))\n",
    "            )\n",
    "            \n",
    "            hit_features = [\n",
    "                'Danceability', 'Energy', 'Valence', 'Tempo', 'Loudness',\n",
    "                'audio_positivity', 'duration_minutes', 'youtube_engagement'\n",
    "            ]\n",
    "            hit_input_example = self.df[hit_features].iloc[:5].fillna(0)\n",
    "            \n",
    "            mlflow.sklearn.log_model(\n",
    "                hit_model,\n",
    "                name=\"hit_model\",\n",
    "                input_example=hit_input_example,\n",
    "                signature=mlflow.models.infer_signature(hit_input_example, hit_model.predict(hit_input_example))\n",
    "            )\n",
    "            \n",
    "            youtube_features = [\n",
    "                'Danceability', 'Energy', 'Valence', 'Tempo', \n",
    "                'audio_positivity', 'duration_minutes', 'log_streams'\n",
    "            ]\n",
    "            valid_data = self.df[self.df['Views'] > 0]\n",
    "            youtube_input_example = valid_data[youtube_features].iloc[:5].fillna(0)\n",
    "            \n",
    "            mlflow.sklearn.log_model(\n",
    "                youtube_model,\n",
    "                name=\"youtube_model\",\n",
    "                input_example=youtube_input_example,\n",
    "                signature=mlflow.models.infer_signature(youtube_input_example, youtube_model.predict(youtube_input_example))\n",
    "            )\n",
    "            \n",
    "            # 피처 중요도 저장\n",
    "            self.feature_importance = self._get_feature_importance()\n",
    "            mlflow.log_dict(self.feature_importance, \"feature_importance.json\")\n",
    "            \n",
    "            # 모델을 pickle로도 저장 (배포용)\n",
    "            with open('models/stream_model.pkl', 'wb') as f:\n",
    "                pickle.dump(stream_model, f)\n",
    "            with open('models/hit_model.pkl', 'wb') as f:\n",
    "                pickle.dump(hit_model, f)\n",
    "            with open('models/youtube_model.pkl', 'wb') as f:\n",
    "                pickle.dump(youtube_model, f)\n",
    "            \n",
    "            # 모델 메타데이터 저장\n",
    "            model_metadata = {\n",
    "                'models': list(self.models.keys()),\n",
    "                'metrics': self.model_metrics,\n",
    "                'feature_importance': self.feature_importance,\n",
    "                'training_timestamp': datetime.now().isoformat()\n",
    "            }\n",
    "            \n",
    "            with open('models/model_metadata.json', 'w') as f:\n",
    "                json.dump(model_metadata, f, indent=2)\n",
    "            \n",
    "            logger.info(\" MLflow 모델 기록 완료!\")\n",
    "            \n",
    "        return self.models\n",
    "    \n",
    "    def _build_stream_prediction_model(self):\n",
    "        \"\"\"스트림 예측 모델 구축\"\"\"\n",
    "        stream_features = [\n",
    "            'Danceability', 'Energy', 'Valence', 'Tempo', 'Loudness',\n",
    "            'Speechiness', 'Acousticness', 'Instrumentalness', 'Liveness',\n",
    "            'duration_minutes', 'audio_positivity', 'audio_complexity',\n",
    "            'log_views', 'youtube_engagement'\n",
    "        ]\n",
    "        \n",
    "        X = self.df[stream_features].fillna(0)\n",
    "        y = self.df['log_streams']\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        \n",
    "        # Random Forest 모델\n",
    "        model = RandomForestRegressor(n_estimators=200, max_depth=15, random_state=42)\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # 예측 및 평가\n",
    "        y_pred = model.predict(X_test)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        \n",
    "        # Cross-validation\n",
    "        cv_scores = cross_val_score(model, X, y, cv=3, scoring='r2')\n",
    "        \n",
    "        metrics = {\n",
    "            'stream_r2': r2,\n",
    "            'stream_mse': mse,\n",
    "            'stream_cv_mean': cv_scores.mean(),\n",
    "            'stream_cv_std': cv_scores.std()\n",
    "        }\n",
    "        \n",
    "        # MLflow 파라미터 로깅\n",
    "        mlflow.log_params({\n",
    "            'stream_n_estimators': 200,\n",
    "            'stream_max_depth': 15,\n",
    "            'stream_features_count': len(stream_features)\n",
    "        })\n",
    "        \n",
    "        return model, metrics\n",
    "    \n",
    "    def _build_hit_prediction_model(self):\n",
    "        \"\"\"히트 예측 모델 구축\"\"\"\n",
    "        # 히트 정의 (상위 10%)\n",
    "        self.df['is_hit'] = (self.df['Stream'] > self.df['Stream'].quantile(0.9)).astype(int)\n",
    "        \n",
    "        hit_features = [\n",
    "            'Danceability', 'Energy', 'Valence', 'Tempo', 'Loudness',\n",
    "            'audio_positivity', 'duration_minutes', 'youtube_engagement'\n",
    "        ]\n",
    "        \n",
    "        X = self.df[hit_features].fillna(0)\n",
    "        y = self.df['is_hit']\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        \n",
    "        model = RandomForestClassifier(n_estimators=200, max_depth=10, random_state=42)\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        y_pred = model.predict(X_test)\n",
    "        report = classification_report(y_test, y_pred, output_dict=True)\n",
    "        \n",
    "        metrics = {\n",
    "            'hit_accuracy': report['accuracy'],\n",
    "            'hit_precision': report['weighted avg']['precision'],\n",
    "            'hit_recall': report['weighted avg']['recall'],\n",
    "            'hit_f1': report['weighted avg']['f1-score']\n",
    "        }\n",
    "        \n",
    "        mlflow.log_params({\n",
    "            'hit_n_estimators': 200,\n",
    "            'hit_max_depth': 10,\n",
    "            'hit_threshold': 0.9\n",
    "        })\n",
    "        \n",
    "        return model, metrics\n",
    "    \n",
    "    def _build_youtube_prediction_model(self):\n",
    "        \"\"\"YouTube 성과 예측 모델 구축\"\"\"\n",
    "        youtube_features = [\n",
    "            'Danceability', 'Energy', 'Valence', 'Tempo', \n",
    "            'audio_positivity', 'duration_minutes', 'log_streams'\n",
    "        ]\n",
    "        \n",
    "        valid_data = self.df[self.df['Views'] > 0]\n",
    "        X = valid_data[youtube_features].fillna(0)\n",
    "        y = valid_data['log_views']\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        \n",
    "        model = RandomForestRegressor(n_estimators=150, max_depth=12, random_state=42)\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        y_pred = model.predict(X_test)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        \n",
    "        metrics = {\n",
    "            'youtube_r2': r2,\n",
    "            'youtube_mse': mse\n",
    "        }\n",
    "        \n",
    "        mlflow.log_params({\n",
    "            'youtube_n_estimators': 150,\n",
    "            'youtube_max_depth': 12\n",
    "        })\n",
    "        \n",
    "        return model, metrics\n",
    "    \n",
    "    def _get_feature_importance(self):\n",
    "        \"\"\"피처 중요도 계산\"\"\"\n",
    "        if 'stream_model' in self.models:\n",
    "            stream_features = [\n",
    "                'Danceability', 'Energy', 'Valence', 'Tempo', 'Loudness',\n",
    "                'Speechiness', 'Acousticness', 'Instrumentalness', 'Liveness',\n",
    "                'duration_minutes', 'audio_positivity', 'audio_complexity',\n",
    "                'log_views', 'youtube_engagement'\n",
    "            ]\n",
    "            \n",
    "            importance_dict = dict(zip(\n",
    "                stream_features,\n",
    "                self.models['stream_model'].feature_importances_.tolist()\n",
    "            ))\n",
    "            \n",
    "            return importance_dict\n",
    "        return {}\n",
    "    \n",
    "    def generate_executive_report(self):\n",
    "        logger.info(\" 경영진 리포트 생성 중...\")\n",
    "        \n",
    "        report = {\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'dataset_overview': {\n",
    "                'total_tracks': len(self.df),\n",
    "                'unique_artists': self.df['Artist'].nunique(),\n",
    "                'total_streams': int(self.df['Stream'].sum()),\n",
    "                'total_views': int(self.df['Views'].sum()),\n",
    "                'data_quality_score': (1 - self.df.isnull().sum().sum() / (len(self.df) * len(self.df.columns))) * 100\n",
    "            },\n",
    "            'performance_metrics': self.kpis,\n",
    "            'model_performance': self.model_metrics\n",
    "        }\n",
    "        \n",
    "        with open('reports/executive_report.json', 'w') as f:\n",
    "            json.dump(report, f, indent=2)\n",
    "        \n",
    "      \n",
    "        \n",
    "        print(f\" 데이터셋:\")\n",
    "        print(f\"   • 총 트랙 수: {report['dataset_overview']['total_tracks']:,}\")\n",
    "        print(f\"   • 총 아티스트 수: {report['dataset_overview']['unique_artists']:,}\")\n",
    "        print(f\"   • 총 스트림 수: {report['dataset_overview']['total_streams']:,}\")\n",
    "        print(f\"   • 총 조회수: {report['dataset_overview']['total_views']:,}\")\n",
    "        print(f\"   • 데이터 품질 점수: {report['dataset_overview']['data_quality_score']:.1f}%\")\n",
    "        print()\n",
    "        \n",
    "        print(f\" 핵심 비즈니스 지표:\")\n",
    "        print(f\"   • 평균 스트림/트랙: {self.kpis.get('avg_streams_per_track', 0):,.0f}\")\n",
    "        print(f\"   • 크로스 플랫폼 상관관계: {self.kpis.get('cross_platform_correlation', 0):.3f}\")\n",
    "        print(f\"   • 평균 참여율: {self.kpis.get('avg_engagement_rate', 0)*100:.2f}%\")\n",
    "        print(f\"   • 아티스트 다양성 지수: {self.kpis.get('artist_diversity', 0):.3f}\")\n",
    "        if 'official_video_lift' in self.kpis:\n",
    "            print(f\"   • 공식 비디오 효과: +{self.kpis['official_video_lift']*100:.1f}%\")\n",
    "        print()\n",
    "        \n",
    "        print(f\" 모델 성능:\")\n",
    "        if self.model_metrics:\n",
    "            print(f\"   • 스트림 예측 R²: {self.model_metrics.get('stream_r2', 0):.3f}\")\n",
    "            print(f\"   • 히트 예측 정확도: {self.model_metrics.get('hit_accuracy', 0)*100:.1f}%\")\n",
    "            print(f\"   • YouTube 예측 R²: {self.model_metrics.get('youtube_r2', 0):.3f}\")\n",
    "        print()\n",
    "        \n",
    "        print(f\" 오디오 트렌드:\")\n",
    "        print(f\"   • 평균 댄서빌리티: {self.kpis.get('avg_danceability', 0):.3f}\")\n",
    "        print(f\"   • 평균 에너지: {self.kpis.get('avg_energy', 0):.3f}\")\n",
    "        print(f\"   • 평균 감정가: {self.kpis.get('avg_valence', 0):.3f}\")\n",
    "        print(f\"   • 평균 템포: {self.kpis.get('avg_tempo', 0):.0f} BPM\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        return report\n",
    "    \n",
    "    def run_complete_analysis(self):\n",
    "        logger.info(\" 전체 분석 파이프라인 시작\")\n",
    "        \n",
    "        start_time = datetime.now()\n",
    "        \n",
    "        try:\n",
    "            # 1. KPI 계산\n",
    "            self.calculate_comprehensive_kpis()\n",
    "            \n",
    "            # 2. 예측 모델 구축\n",
    "            self.build_prediction_models_with_mlflow()\n",
    "            \n",
    "            # 3. 경영진 리포트\n",
    "            report = self.generate_executive_report()\n",
    "            \n",
    "            self.df.to_csv('data/processed_spotify_youtube.csv', index=False)\n",
    "            \n",
    "            end_time = datetime.now()\n",
    "            execution_time = (end_time - start_time).total_seconds()\n",
    "            \n",
    "            # 최종 실행 요약\n",
    "            execution_summary = {\n",
    "                'start_time': start_time.isoformat(),\n",
    "                'end_time': end_time.isoformat(),\n",
    "                'execution_time_seconds': execution_time,\n",
    "                'status': 'SUCCESS',\n",
    "                'models_created': len(self.models),\n",
    "                'data_rows': len(self.df)\n",
    "            }\n",
    "            \n",
    "            with open('reports/execution_summary.json', 'w') as f:\n",
    "                json.dump(execution_summary, f, indent=2)\n",
    "            \n",
    "            logger.info(f\" 전체 분석 완료! 실행 시간: {execution_time:.2f}초\")\n",
    "            \n",
    "            \n",
    "            print(f\"  실행 시간: {execution_time:.2f}초\")\n",
    "            print(f\" 생성된 모델: {len(self.models)}개\")\n",
    "            print(f\" 처리된 데이터: {len(self.df):,}행\")\n",
    "            print(\"\\n 생성된 파일:\")\n",
    "            print(\"   • models/ - 머신러닝 모델\")\n",
    "            print(\"   • reports/ - 분석 리포트\")\n",
    "            print(\"   • data/ - 처리된 데이터\")\n",
    "            print(\"   • mlruns/ - MLflow 실험 기록\")\n",
    "            print(\"\\n next:\")\n",
    "            print(\"   • Streamlit 대시보드: streamlit run dashboard.py\")\n",
    "            print(\"   • MLflow UI: mlflow ui\")\n",
    "            print(\"=\"*60)\n",
    "            \n",
    "            return execution_summary\n",
    "            \n",
    "        except Exception as e:\n",
    "            error_summary = {\n",
    "                'start_time': start_time.isoformat(),\n",
    "                'error_time': datetime.now().isoformat(),\n",
    "                'status': 'ERROR',\n",
    "                'error_message': str(e),\n",
    "                'execution_time_seconds': (datetime.now() - start_time).total_seconds()\n",
    "            }\n",
    "            \n",
    "            logger.error(f\" 분석 중 오류 발생: {str(e)}\")\n",
    "            \n",
    "            with open('reports/error_log.json', 'w') as f:\n",
    "                json.dump(error_summary, f, indent=2)\n",
    "            \n",
    "            raise\n",
    "        \n",
    "        finally:\n",
    "            if self.conn:\n",
    "                self.conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2032ccf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-31 21:34:51,523 - INFO - 디렉토리 생성/확인: models\n",
      "2025-10-31 21:34:51,526 - INFO - 디렉토리 생성/확인: reports\n",
      "2025-10-31 21:34:51,527 - INFO - 디렉토리 생성/확인: data\n",
      "2025-10-31 21:34:51,529 - INFO - 디렉토리 생성/확인: mlruns\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spotify-YouTube 통합 분석 시스템 시작\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-31 21:34:51,991 - INFO - 데이터셋 크기: (20718, 28)\n",
      "2025-10-31 21:34:52,028 - INFO - 이상치 제거: 20718 → 19376 행\n",
      "2025-10-31 21:34:52,409 - INFO -  전처리 완료 - 최종 데이터 크기: (19376, 37)\n",
      "2025-10-31 21:34:52,410 - INFO -  전체 분석 파이프라인 시작\n",
      "2025-10-31 21:34:52,411 - INFO -  KPI 계산\n",
      "2025-10-31 21:34:52,430 - INFO -  MLflow와 함께 예측 모델 구축\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6eafe7f5ab64a198ca3312cf2318d9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4321f70909af4f65bd07c0047c6da154",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a01362b9f97647a592072822b75f7c7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-31 21:38:05,996 - INFO -  MLflow 모델 기록 완료!\n",
      "2025-10-31 21:38:06,002 - INFO -  경영진 리포트 생성 중...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 데이터셋:\n",
      "   • 총 트랙 수: 19,376\n",
      "   • 총 아티스트 수: 2,076\n",
      "   • 총 스트림 수: 1,774,355,067,032\n",
      "   • 총 조회수: 874,786,101,040\n",
      "   • 데이터 품질 점수: 99.7%\n",
      "\n",
      " 핵심 비즈니스 지표:\n",
      "   • 평균 스트림/트랙: 91,574,890\n",
      "   • 크로스 플랫폼 상관관계: 0.456\n",
      "   • 평균 참여율: 1.21%\n",
      "   • 아티스트 다양성 지수: 0.107\n",
      "   • 공식 비디오 효과: +31.4%\n",
      "\n",
      " 모델 성능:\n",
      "   • 스트림 예측 R²: 0.127\n",
      "   • 히트 예측 정확도: 89.7%\n",
      "   • YouTube 예측 R²: 0.351\n",
      "\n",
      " 오디오 트렌드:\n",
      "   • 평균 댄서빌리티: 0.616\n",
      "   • 평균 에너지: 0.632\n",
      "   • 평균 감정가: 0.530\n",
      "   • 평균 템포: 121 BPM\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-31 21:38:06,860 - INFO -  전체 분석 완료! 실행 시간: 194.45초\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  실행 시간: 194.45초\n",
      " 생성된 모델: 3개\n",
      " 처리된 데이터: 19,376행\n",
      "\n",
      " 생성된 파일:\n",
      "   • models/ - 머신러닝 모델\n",
      "   • reports/ - 분석 리포트\n",
      "   • data/ - 처리된 데이터\n",
      "   • mlruns/ - MLflow 실험 기록\n",
      "\n",
      " next:\n",
      "   • Streamlit 대시보드: streamlit run dashboard.py\n",
      "   • MLflow UI: mlflow ui\n",
      "============================================================\n",
      "\n",
      " Analy\n",
      "자세한 결과는 MLflow UI : mlflow ui\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    try:\n",
    "        \n",
    "        csv_file = r'C:\\Users\\color\\Desktop\\KPI\\Spotify_Youtube.csv'\n",
    "        \n",
    "        \n",
    "        if not os.path.exists(csv_file):\n",
    "            print(f\" 파일을 찾을 수 없습니다: {csv_file}\")\n",
    "            print(\"파일 경로를 확인하세요.\")\n",
    "            return\n",
    "        \n",
    "        analyzer = SpotifyYouTubeAnalytics(csv_file)\n",
    "        summary = analyzer.run_complete_analysis()\n",
    "        \n",
    "        print(f\"자세한 결과는 MLflow UI : mlflow ui\")\n",
    "        \n",
    "        return summary\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\" 실행 중 오류: {str(e)}\")\n",
    "        print(f\"오류 발생: {str(e)}\")\n",
    "        print(\"자세한 오류 로그는 reports/error_log.json\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
